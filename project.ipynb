{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f900ad10",
   "metadata": {},
   "source": [
    "Vamos a querer unificar todos los datos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dd02fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3d70c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidInputException",
     "evalue": "Invalid Input Error: CSV Error on Line: 4\nOriginal Line: \n\"14\",\"1\",\"F10\",\" \",\"12_55 a 59\",\"1\"\nInvalid unicode (byte sequence mismatch) detected. This file is not utf-8 encoded.\n\nPossible Solution: Set the correct encoding, if available, to read this CSV File (e.g., encoding='UTF-16')\nPossible Solution: Enable ignore errors (ignore_errors=true) to skip this row\n\n  file = datasets/defweb05.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = (empty) (Auto-Detected)\n  new_line = Single-Line File (Auto-Detected)\n  header = false (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  comment = (empty) (Auto-Detected)\n  strict_mode = true (Auto-Detected)\n  date_format =  (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding = 0\n  sample_size = 20480\n  ignore_errors = false\n  all_varchar = 0\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidInputException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mduckdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;43m    CREATE TABLE def2005 AS\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;43m    SELECT * FROM \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/defweb05.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInvalidInputException\u001b[0m: Invalid Input Error: CSV Error on Line: 4\nOriginal Line: \n\"14\",\"1\",\"F10\",\" \",\"12_55 a 59\",\"1\"\nInvalid unicode (byte sequence mismatch) detected. This file is not utf-8 encoded.\n\nPossible Solution: Set the correct encoding, if available, to read this CSV File (e.g., encoding='UTF-16')\nPossible Solution: Enable ignore errors (ignore_errors=true) to skip this row\n\n  file = datasets/defweb05.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = (empty) (Auto-Detected)\n  new_line = Single-Line File (Auto-Detected)\n  header = false (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  comment = (empty) (Auto-Detected)\n  strict_mode = true (Auto-Detected)\n  date_format =  (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding = 0\n  sample_size = 20480\n  ignore_errors = false\n  all_varchar = 0\n\n"
     ]
    }
   ],
   "source": [
    "duckdb.sql(\n",
    "    \"create\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2643e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing datasets\\defweb05.csv ...\n",
      "Processing datasets\\defweb06.csv ...\n",
      "Processing datasets\\defweb07.csv ...\n",
      "Processing datasets\\defweb08.csv ...\n",
      "Processing datasets\\defweb09.csv ...\n",
      "Processing datasets\\defweb10.csv ...\n",
      "Processing datasets\\defweb11.csv ...\n",
      "Processing datasets\\defweb12.csv ...\n",
      "Processing datasets\\defweb13.csv ...\n",
      "Processing datasets\\defweb14.csv ...\n",
      "Processing datasets\\defweb15.csv ...\n",
      "Processing datasets\\defweb16.csv ...\n",
      "Processing datasets\\defweb17.csv ...\n",
      "Processing datasets\\defweb18.csv ...\n",
      "Processing datasets\\defweb19.csv ...\n",
      "Processing datasets\\defweb20_0.csv ...\n",
      "Processing datasets\\defweb21_0.csv ...\n",
      "Processing datasets\\defweb22_0.csv ...\n",
      "Processing datasets\\defweb23.csv ...\n",
      "All CSVs imported into SQL successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# CONFIGURE YOUR DATABASE\n",
    "# --------------------------\n",
    "# Examples:\n",
    "# SQLite:\n",
    "engine = create_engine(\"sqlite:///defunciones.db\")\n",
    "\n",
    "# PostgreSQL:\n",
    "# engine = create_engine(\"postgresql://user:password@localhost:5432/mydb\")\n",
    "\n",
    "# MySQL:\n",
    "# engine = create_engine(\"mysql+pymysql://user:password@localhost:3306/mydb\")\n",
    "\n",
    "# --------------------------\n",
    "# FOLDER WITH YOUR CSV FILES\n",
    "# --------------------------\n",
    "folder = \"datasets\"\n",
    "\n",
    "def detect_encoding(path):\n",
    "    \"\"\"Detect encoding of a file using chardet.\"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read(50000)\n",
    "    return chardet.detect(raw)[\"encoding\"]\n",
    "\n",
    "\n",
    "combined = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        path = os.path.join(folder, file)\n",
    "        print(f\"Processing {path} ...\")\n",
    "\n",
    "        enc = detect_encoding(path)\n",
    "\n",
    "        df = pd.read_csv(path, encoding=enc)\n",
    "\n",
    "        # Normalize column names\n",
    "        df.columns = (\n",
    "            df.columns.str.lower()\n",
    "            .str.strip()\n",
    "            .str.replace(\" \", \"_\")\n",
    "            .str.replace(\".\", \"_\")\n",
    "        )\n",
    "\n",
    "        # Try to infer year from filename (e.g. defweb05 → 2005)\n",
    "        year_digits = \"\".join([c for c in file if c.isdigit()])\n",
    "        if len(year_digits) == 2:\n",
    "            year = 2000 + int(year_digits)\n",
    "        elif len(year_digits) == 4:\n",
    "            year = int(year_digits)\n",
    "        else:\n",
    "            year = None\n",
    "\n",
    "        df[\"year\"] = year\n",
    "\n",
    "        combined.append(df)\n",
    "\n",
    "# Concatenate all data\n",
    "df_all = pd.concat(combined, ignore_index=True)\n",
    "\n",
    "# Upload to SQL\n",
    "df_all.to_sql(\"defunciones\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"All CSVs imported into SQL successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfde5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVRES</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>CAUSA</th>\n",
       "      <th>MAT</th>\n",
       "      <th>GRUPEDAD</th>\n",
       "      <th>CUENTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>R99</td>\n",
       "      <td></td>\n",
       "      <td>11_50 a 54</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>F10</td>\n",
       "      <td></td>\n",
       "      <td>12_55 a 59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>N05</td>\n",
       "      <td></td>\n",
       "      <td>17_80 y más</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>C26</td>\n",
       "      <td></td>\n",
       "      <td>17_80 y más</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>G30</td>\n",
       "      <td></td>\n",
       "      <td>13_60 a 64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45562</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>E14</td>\n",
       "      <td></td>\n",
       "      <td>10_45 a 49</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45563</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>K66</td>\n",
       "      <td></td>\n",
       "      <td>09_40 a 44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45564</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>J69</td>\n",
       "      <td></td>\n",
       "      <td>09_40 a 44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45565</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>R99</td>\n",
       "      <td></td>\n",
       "      <td>13_60 a 64</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45566</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>R55</td>\n",
       "      <td></td>\n",
       "      <td>02_1 a 9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45567 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PROVRES  SEXO CAUSA MAT     GRUPEDAD  CUENTA\n",
       "0           50     2   R99       11_50 a 54      10\n",
       "1           14     1   F10       12_55 a 59       1\n",
       "2           62     1   N05      17_80 y más       1\n",
       "3           74     2   C26      17_80 y más       3\n",
       "4            6     1   G30       13_60 a 64       3\n",
       "...        ...   ...   ...  ..          ...     ...\n",
       "45562        6     1   E14       10_45 a 49      27\n",
       "45563       46     2   K66       09_40 a 44       1\n",
       "45564       30     1   J69       09_40 a 44       1\n",
       "45565       14     2   R99       13_60 a 64       6\n",
       "45566       90     1   R55         02_1 a 9       1\n",
       "\n",
       "[45567 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select * from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
